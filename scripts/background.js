console.log('[BACKGROUND_SCRIPT] background.js script started');
// èƒŒæ™¯è…³æœ¬ç‹€æ…‹ç®¡ç†
let captureState = {
  isCapturing: false,
  activeTeamId: null,
  captureMode: null,
  startTime: null,
  segmentNumber: 0,  // Track segment number to help with file naming
  downloadFiles: false, // æŽ§åˆ¶æ˜¯å¦ä¸‹è¼‰éŸ³è¨Šæª”æ¡ˆ
  transcriptChunks: [], // å„²å­˜è½‰éŒ„ç‰‡æ®µä»¥ä¾¿popupé‡æ–°æ‰“é–‹æ™‚æ¢å¾©
  lastScreenshotDataUrl: null
};

// éŒ„éŸ³ç›¸é—œ
let captureStream = null;
let mediaRecorder = null;
let audioChunks = [];
let transcribeInterval = null;
let screenshotInterval = null; // æˆªåœ–é–“éš”è¨ˆæ™‚å™¨
let activeTabId = null;
let recordingActiveTab = null; // Store the active tab ID we're recording from

// åˆå§‹åŒ–ç›£è½å™¨
chrome.runtime.onInstalled.addListener(() => {
  console.log('AI Hackathon Judge æ“´å±•å·²å®‰è£');
  console.log('[BACKGROUND_SCRIPT] onInstalled listener triggered');
});

// è¨Šæ¯è™•ç†
chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
  console.log('Background received message:', message, 'from sender:', sender);
  
  switch (message.action) {
    case 'getCaptureState':
      console.log('[BACKGROUND_SCRIPT] Action: getCaptureState. Current captureState:', JSON.stringify(captureState));
      sendResponse({
        isCapturing: captureState.isCapturing,
        activeTeamId: captureState.activeTeamId,
        transcriptChunks: captureState.transcriptChunks
      });
      break;
      
    case 'startCapture':
      console.log('[BACKGROUND_SCRIPT] Action: startCapture. Received options:', JSON.stringify(message.options));
      console.log('[BACKGROUND_SCRIPT] Checking MediaRecorder MIME type support:');
      console.log(`  audio/webm: ${MediaRecorder.isTypeSupported('audio/webm')}`);
      console.log(`  audio/opus: ${MediaRecorder.isTypeSupported('audio/opus')}`); // Opus is often used in webm
      console.log(`  audio/ogg; codecs=opus: ${MediaRecorder.isTypeSupported('audio/ogg; codecs=opus')}`);
      console.log(`  audio/mpeg: ${MediaRecorder.isTypeSupported('audio/mpeg')}`); // For MP3
      console.log(`  audio/mp3: ${MediaRecorder.isTypeSupported('audio/mp3')}`);   // Also for MP3
      try {
        // å¦‚æžœå·²ç¶“åœ¨æ•ç²ï¼Œå…ˆåœæ­¢
        if (captureState.isCapturing) {
          console.log('[BACKGROUND_SCRIPT] Already capturing, stopping existing capture first.');
          stopCapturing();
        }
        
        // Store state before starting capture
        captureState.isCapturing = true;
        captureState.activeTeamId = message.options.teamId;
        console.log(`[BACKGROUND_SCRIPT] captureState.activeTeamId explicitly set to: ${captureState.activeTeamId} from message options.`);
        captureState.captureMode = message.options.captureMode;
        captureState.startTime = Date.now();
        captureState.segmentNumber = 0; // Reset segment counter
        captureState.downloadFiles = message.options.downloadFiles || false; // è¨­ç½®æ˜¯å¦ä¸‹è¼‰æª”æ¡ˆ
        captureState.transcriptChunks = []; // é‡ç½®è½‰éŒ„ç‰‡æ®µ
        console.log(`[BACKGROUND_SCRIPT] Download files set to: ${captureState.downloadFiles}`);
        console.log('[BACKGROUND_SCRIPT] captureState after updates in startCapture:', JSON.stringify(captureState));
        
        // Start the first segment capture - this will also set the recordingActiveTab value
        captureNewSegment();
        
        // Set interval to capture new segments every 10 seconds
        transcribeInterval = setInterval(() => {
          if (captureState.isCapturing) {
            // æ£€æŸ¥æ‰©å±•æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
            if (!chrome.tabCapture || typeof chrome.tabCapture.capture !== 'function') {
              console.error('[BACKGROUND_SCRIPT] Extension appears to be disabled during recording. Stopping audio capture.');
              chrome.runtime.sendMessage({
                action: 'extensionDisabled',
                error: 'Extension became disabled during recording. Audio transcription stopped.'
              });
              // æ¸…é™¤éŸ³é¢‘ç›¸å…³çš„é—´éš”ï¼Œä½†ä¿ç•™æˆªå›¾åŠŸèƒ½
              if (transcribeInterval) {
                clearInterval(transcribeInterval);
                transcribeInterval = null;
              }
              return;
            }
            
            // Stop current recording if it exists
            if (mediaRecorder && mediaRecorder.state === 'recording') {
              console.log('[BACKGROUND_SCRIPT] Stopping current segment recording to start a new one');
              mediaRecorder.stop();
              
              // Start a new capture immediately to reduce delay
              // This will create overlap rather than gaps
              captureNewSegment();
            } else {
              // If there's no active recording for some reason, start one
              captureNewSegment();
            }
          }
        }, 10000);
        
        // Set interval to capture screenshots every 10 seconds
        screenshotInterval = setInterval(() => {
          if (captureState.isCapturing) {
            // Check if screenshot analysis is enabled
            getFromStorage('enable_screenshot_analysis').then(enableScreenshotAnalysis => {
              if (enableScreenshotAnalysis !== 'false') {
                captureScreenshot();
              }
            });
          }
        }, 10000);
        
        sendResponse({ success: true });
      } catch (error) {
        console.error('é–‹å§‹æ•ç²å¤±æ•—:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;
      
    case 'stopCapture':
      console.log('[BACKGROUND_SCRIPT] Action: stopCapture. Current captureState before stop:', JSON.stringify(captureState));
      try {
        stopCapturing();
        sendResponse({ success: true });
        console.log('[BACKGROUND_SCRIPT] stopCapture successful. captureState after stop:', JSON.stringify(captureState));
      } catch (error) {
        console.error('åœæ­¢æ•ç²å¤±æ•—:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;
      
    case 'setActiveTeam':
      console.log('[BACKGROUND_SCRIPT] Action: setActiveTeam. Received teamId:', message.teamId, '. Current captureState:', JSON.stringify(captureState));
      try {
        if (!captureState.isCapturing) {
          captureState.activeTeamId = message.teamId;
          console.log('[BACKGROUND_SCRIPT] setActiveTeam: captureState.activeTeamId updated to:', captureState.activeTeamId);
          sendResponse({ success: true });
        } else {
          console.warn('[BACKGROUND_SCRIPT] setActiveTeam: Cannot change team while capturing is active. captureState:', JSON.stringify(captureState));
          sendResponse({ 
            success: false, 
            error: 'Cannot change team while capturing is active' 
          });
        }
      } catch (error) {
        console.error('è¨­ç½®åœ˜éšŠå¤±æ•—:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;
      
    case 'transcriptComplete':
      console.log('[BACKGROUND_SCRIPT] Action: transcriptComplete. Received transcript:', message.transcript);
      try {
        // å°‡è½‰éŒ„çµæžœä¿å­˜åˆ° background state
        captureState.transcriptChunks.push(message.transcript);
        console.log('[BACKGROUND_SCRIPT] transcriptComplete: saved transcript chunk. Total chunks:', captureState.transcriptChunks.length);
        
        // é€šçŸ¥æ‰€æœ‰æ‰“é–‹çš„ extension é é¢æ›´æ–°
        chrome.runtime.sendMessage({
          action: 'transcriptUpdated',
          transcriptChunks: captureState.transcriptChunks
        });
        
        sendResponse({ success: true });
      } catch (error) {
        console.error('[BACKGROUND_SCRIPT] transcriptComplete error:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;

    case 'clearTranscripts':
      console.log('[BACKGROUND_SCRIPT] Action: clearTranscripts');
      try {
        captureState.transcriptChunks = [];
        console.log('[BACKGROUND_SCRIPT] clearTranscripts: cleared all transcript chunks');
        sendResponse({ success: true });
      } catch (error) {
        console.error('[BACKGROUND_SCRIPT] clearTranscripts error:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;

    case 'testScreenshot':
      console.log('[BACKGROUND_SCRIPT] Action: testScreenshot');
      try {
        // Force capture a screenshot for testing
        captureScreenshot().then(() => {
          sendResponse({ success: true });
        }).catch((error) => {
          console.error('[BACKGROUND_SCRIPT] Test screenshot failed:', error);
          sendResponse({ success: false, error: error.message });
        });
        return true; // Will respond asynchronously
      } catch (error) {
        console.error('[BACKGROUND_SCRIPT] testScreenshot error:', error);
        sendResponse({ success: false, error: error.message });
      }
      break;

    default:
      sendResponse({ success: false, error: 'Unknown action' });
  }
  
  // ç‚ºç•°æ­¥éŸ¿æ‡‰è¿”å›ž true
  return true;
});

// Function to capture a new segment with a fresh stream
function captureNewSegment() {
  console.log('[BACKGROUND_SCRIPT] Starting new segment capture');
  
  // æ£€æŸ¥æ‰©å±•æ˜¯å¦å…·æœ‰å¿…è¦çš„æƒé™å’ŒåŠŸèƒ½
  if (!chrome.tabCapture || typeof chrome.tabCapture.capture !== 'function') {
    console.error('[BACKGROUND_SCRIPT] Extension appears to be disabled or tabCapture API is not available');
    // é€šçŸ¥ç”¨æˆ·æ‰©å±•å¯èƒ½å·²è¢«ç¦ç”¨
    chrome.runtime.sendMessage({
      action: 'extensionDisabled',
      error: 'Chrome extension appears to be disabled. Audio transcription will not work.'
    });
    return;
  }
  
  // First check if we're still on the tab we want to record
  chrome.tabs.query({active: true, currentWindow: true}, function(tabs) {
    if (tabs.length === 0) {
      console.error('[BACKGROUND_SCRIPT] No active tab found for recording');
      return;
    }
    
    const currentActiveTab = tabs[0].id;
    
    // If this is the first segment, set recordingActiveTab
    if (!recordingActiveTab) {
      recordingActiveTab = currentActiveTab;
      console.log(`[BACKGROUND_SCRIPT] Recording from active tab with ID: ${recordingActiveTab}`);
    } else if (currentActiveTab !== recordingActiveTab) {
      console.warn(`[BACKGROUND_SCRIPT] WARNING: Active tab has changed from ${recordingActiveTab} to ${currentActiveTab}. Please return to the original tab for best results.`);
      // We could send a notification to the popup here to alert the user
    }
    
    // å•Ÿå‹•æ•ç²ç¨‹åº
    console.log('[BACKGROUND_SCRIPT] Attempting to start capture. Checking chrome.tabCapture object:', chrome.tabCapture);
    if (chrome.tabCapture && typeof chrome.tabCapture.capture === 'function') {
      console.log('[BACKGROUND_SCRIPT] chrome.tabCapture.capture IS a function.');
    } else {
      console.error('[BACKGROUND_SCRIPT] chrome.tabCapture.capture IS NOT a function or chrome.tabCapture is undefined.');
      return;
    }
    
    // NOTE: chrome.tabCapture.capture can only capture the currently active tab
    // It does not support specifying a tabId, so we removed that parameter
    chrome.tabCapture.capture({ audio: true, video: false }, stream => {
      if (!stream) {
        console.error('[BACKGROUND_SCRIPT] Failed to capture tab audio for new segment');
        // é€šçŸ¥ç”¨æˆ·éŸ³é¢‘æ•èŽ·å¤±è´¥
        chrome.runtime.sendMessage({
          action: 'audioCaptureError',
          error: 'Failed to capture audio. Please check if the extension is enabled and has proper permissions.'
        });
        return;
      }
      console.log('[BACKGROUND_SCRIPT] Tab capture successful for new segment, stream obtained.');
      
      console.log('[BACKGROUND_SCRIPT] Attempting to inspect audio tracks...');
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length > 0) {
        audioTracks.forEach((track, index) => {
          console.log(`[BACKGROUND_SCRIPT] Audio Track ${index}: id=${track.id}, label='${track.label}', enabled=${track.enabled}, muted=${track.muted}, readyState='${track.readyState}'`);
          // Log when track events occur DURING the recording
          track.onended = () => console.error(`[BACKGROUND_SCRIPT] CRITICAL: Audio Track ${index} (ID: ${track.id}) for stream ${stream.id} has ENDED.`);
          track.onmute = () => console.warn(`[BACKGROUND_SCRIPT] WARNING: Audio Track ${index} (ID: ${track.id}) for stream ${stream.id} has been MUTED.`);
          track.onunmute = () => console.log(`[BACKGROUND_SCRIPT] Audio Track ${index} (ID: ${track.id}) for stream ${stream.id} has been UNMUTED.`);
        });
      } else {
        console.warn('[BACKGROUND_SCRIPT] No audio tracks found in the captured stream!');
      }
      console.log('[BACKGROUND_SCRIPT] Finished inspecting audio tracks.');
      
      // å‰µå»ºéŸ³é »ä¸Šä¸‹æ–‡ä¾†é‡æ–°è·¯ç”±éŸ³é »åˆ°æšè²å™¨
      try {
        // Basic audio rerouting - always enabled for now to fix the core issue
        const audioContext = new AudioContext();
        const source = audioContext.createMediaStreamSource(stream);
        
        // å°‡éŸ³é »åŒæ™‚é€£æŽ¥åˆ°æšè²å™¨ï¼ˆç”¨æ–¼æ’­æ”¾ï¼‰å’Œä¿æŒåŽŸå§‹æµï¼ˆç”¨æ–¼éŒ„è£½ï¼‰
        source.connect(audioContext.destination); // é€™æœƒå°‡éŸ³é »è¼¸å‡ºåˆ°æšè²å™¨
        
        console.log('[BACKGROUND_SCRIPT] Audio rerouting to speakers successful');
        
        // é€šçŸ¥ç”¨æˆ¶éŸ³é »å·²é‡æ–°è·¯ç”±
        chrome.runtime.sendMessage({
          action: 'audioReroutingSuccess',
          message: 'Audio is now being captured and played through speakers simultaneously'
        });
      } catch (audioError) {
        console.warn('[BACKGROUND_SCRIPT] Audio rerouting setup failed:', audioError);
        // å¦‚æžœéŸ³é »é‡æ–°è·¯ç”±å¤±æ•—ï¼Œä»ç„¶ç¹¼çºŒéŒ„è£½ï¼Œä½†é€šçŸ¥ç”¨æˆ¶
        chrome.runtime.sendMessage({
          action: 'audioReroutingWarning',
          message: 'Audio capture working but tab audio may be muted. This is normal.'
        });
      }
      
      // Store the new stream
      if (captureStream) {
        // Safely close the old stream before replacing it
        captureStream.getTracks().forEach(track => track.stop());
      }
      captureStream = stream;
      
      // Reset audioChunks for the new segment
      audioChunks = [];
      
      // Increment segment counter
      captureState.segmentNumber++;
      console.log(`[BACKGROUND_SCRIPT] Recording segment #${captureState.segmentNumber}`);
      
      // è¨­ç½®éŸ³è¨ŠéŒ„è£½
      mediaRecorder = new MediaRecorder(stream);
      
      mediaRecorder.ondataavailable = e => {
        console.log('[BACKGROUND_SCRIPT] ondataavailable triggered.');
        if (e.data.size > 0) {
          audioChunks.push(e.data);
          console.log('æ”¶é›†éŸ³è¨Šå€å¡Š:', audioChunks.length, e.data.size, 'bytes', 'Current audioChunks (sizes):', JSON.stringify(audioChunks.map(chunk => chunk.size)));
        }
      };
      
      mediaRecorder.onerror = (event) => {
        console.error('[BACKGROUND_SCRIPT] MediaRecorder error:', event.error);
      };
      
      mediaRecorder.onstop = () => {
        console.log(`[BACKGROUND_SCRIPT] mediaRecorder.onstop event fired for segment #${captureState.segmentNumber}. Current audioChunks.length:`, audioChunks.length);
        if (audioChunks.length > 0) {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const isFinal = !captureState.isCapturing; // If we're no longer capturing, this is the final segment
          
          // Save the segment
          saveAudioBlobToFile(audioBlob, isFinal ? "final_segment" : "segment");
          
          // æŠŠéŸ³è¨Š blob è½‰æˆ base64 å†å‚³é€
          const reader = new FileReader();
          reader.onloadend = () => {
            const base64data = reader.result.split(',')[1];
            console.log(`[BACKGROUND_SCRIPT] Sending ${isFinal ? 'final ' : ''}audioChunk (from onstop) to popup.`);
            console.log(`[BACKGROUND_SCRIPT] isFinal flag set to: ${isFinal}`);
            
            // Process audio chunk in background instead of sending to popup
            processAudioChunkInBackground(base64data, new Date().toISOString(), isFinal);
          };
          reader.readAsDataURL(audioBlob);
          
          // Clear chunks after processing
          audioChunks = [];
        } else {
          console.log('[BACKGROUND_SCRIPT] mediaRecorder.onstop: No audio chunks to process.');
        }
        
        // Stop stream tracks when done to avoid resource leaks
        if (captureStream && (!captureState.isCapturing || 
            (mediaRecorder && mediaRecorder.state === 'inactive'))) {
          captureStream.getTracks().forEach(track => {
            if (track.readyState === 'live') {
              track.stop();
            }
          });
          captureStream = null;
        }
      };
      
      // Start recording
      mediaRecorder.start();
      console.log(`[BACKGROUND_SCRIPT] MediaRecorder started for segment #${captureState.segmentNumber}`);
    });
  });
}

// åœæ­¢æ‰€æœ‰æ•ç²
function stopCapturing() {
  console.log('[BACKGROUND_SCRIPT] stopCapturing called.');
  
  // Set state flag first so no new segments will start
  captureState.isCapturing = false; 
  
  if (transcribeInterval) {
    clearInterval(transcribeInterval);
    transcribeInterval = null;
    console.log('[BACKGROUND_SCRIPT] Transcribe interval cleared.');
  }
  
  if (screenshotInterval) {
    clearInterval(screenshotInterval);
    screenshotInterval = null;
    console.log('[BACKGROUND_SCRIPT] Screenshot interval cleared.');
  }
  
  if (mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.stop(); // This will trigger ondataavailable with any final data, then onstop
    console.log('[BACKGROUND_SCRIPT] mediaRecorder.stop() called.');
  }
  
  // Clean up stream even if mediaRecorder is not active or not exist
  if (captureStream) {
    captureStream.getTracks().forEach(track => track.stop());
    captureStream = null;
    console.log('[BACKGROUND_SCRIPT] Capture stream tracks stopped.');
  }
  
  console.log('[BACKGROUND_SCRIPT] stopCapturing finished. isCapturing:', captureState.isCapturing);
  
  // Always try to save existing transcript data when stopping, regardless of whether there's a final audio segment
  if (captureState.transcriptChunks.length > 0) {
    console.log('[BACKGROUND_SCRIPT] Found existing transcript chunks, scheduling save operation');
    setTimeout(() => {
      saveTranscriptToTeamInBackground();
    }, 2000); // Give time for any final audio processing to complete
  } else {
    console.log('[BACKGROUND_SCRIPT] No transcript chunks found to save');
  }
  
  // Notify all open extension pages of state change
  chrome.runtime.sendMessage({
    action: 'captureStateChanged',
    state: {
      isCapturing: captureState.isCapturing,
      activeTeamId: captureState.activeTeamId
    }
  });
}

// Helper function to save audio blob to a file
function saveAudioBlobToFile(audioBlob, segmentType) {
  console.log(`[BACKGROUND_SCRIPT] saveAudioBlobToFile called. Current activeTeamId: ${captureState.activeTeamId}, segmentType: ${segmentType}`);
  
  // æª¢æŸ¥æ˜¯å¦è¦ä¸‹è¼‰æª”æ¡ˆï¼Œå¦‚æžœè¨­ç½®ç‚ºä¸ä¸‹è¼‰å‰‡è·³éŽ
  if (!captureState.downloadFiles) {
    console.log('[BACKGROUND_SCRIPT] Download files is disabled. Skipping file save.');
    return;
  }
  
  if (!captureState.activeTeamId) {
    console.warn('[BACKGROUND_SCRIPT] saveAudioBlobToFile: activeTeamId is NOT set. Aborting file save.');
    return;
  }
  console.log(`[BACKGROUND_SCRIPT] saveAudioBlobToFile: activeTeamId is set (${captureState.activeTeamId}). Proceeding to save.`);
  console.log(`[BACKGROUND_SCRIPT] Attempting to save audio file for team: ${captureState.activeTeamId}, segment: ${segmentType}`);

  const timestamp = new Date().toISOString().replace(/:/g, '-'); // Sanitize timestamp for filename
  const filename = `audio_capture/${captureState.activeTeamId}_${segmentType}_${timestamp}.webm`;
  const url = URL.createObjectURL(audioBlob);

  console.log(`[BACKGROUND_SCRIPT] Attempting to download: Filename: '${filename}', Blob URL: '${url}', Blob size: ${audioBlob.size} bytes`);

  chrome.downloads.download({
    url: url,
    filename: filename,
    saveAs: false // Set to true if you want the user to be prompted for save location each time
  }, (downloadId) => {
    if (chrome.runtime.lastError) {
      console.error(`[BACKGROUND_SCRIPT] Error downloading audio file '${filename}':`, chrome.runtime.lastError.message, chrome.runtime.lastError);
    } else {
      console.log(`[BACKGROUND_SCRIPT] Audio segment '${filename}' save initiated. Download ID: ${downloadId || 'N/A (already downloaded or no ID provided)'}`);
    }
    // It's good practice to revoke the object URL, but Chrome handles it for completed downloads.
    // Consider revoking if downloadId is undefined or if an error occurs and the download didn't start.
    // For simplicity, we rely on Chrome's default behavior for now.
    // URL.revokeObjectURL(url); 
  });
}

// æˆªåœ–æ•ç²å‡½æ•¸
function captureScreenshot() {
  console.log('[BACKGROUND_SCRIPT] Starting screenshot capture');
  
  // Check if screenshot analysis is enabled first
  getFromStorage('enable_screenshot_analysis').then(enableScreenshotAnalysis => {
    console.log('[BACKGROUND_SCRIPT] Screenshot analysis enabled:', enableScreenshotAnalysis !== 'false');
    
    if (enableScreenshotAnalysis === 'false') {
      console.log('[BACKGROUND_SCRIPT] Screenshot analysis disabled, skipping capture');
      return;
    }
    
    // ç²å–ç•¶å‰æ´»èºçš„æ¨™ç±¤é 
    chrome.tabs.query({active: true, currentWindow: true}, (tabs) => {
      if (tabs.length === 0) {
        console.error('[BACKGROUND_SCRIPT] No active tab found for screenshot');
        return;
      }
      
      const activeTab = tabs[0];
      
      // æ•ç²å¯è¦‹æ¨™ç±¤é çš„æˆªåœ–
      chrome.tabs.captureVisibleTab(activeTab.windowId, {format: 'jpeg', quality: 85}, (dataUrl) => {
        if (chrome.runtime.lastError) {
          console.error('[BACKGROUND_SCRIPT] Screenshot capture failed:', chrome.runtime.lastError.message);
          return;
        }
        
        console.log('[BACKGROUND_SCRIPT] Screenshot captured successfully');
        
        // èˆ‡å‰ä¸€å¼µæˆªåœ–æ¯”è¼ƒ
        if (captureState.lastScreenshotDataUrl === dataUrl) {
          console.log('[BACKGROUND_SCRIPT] Screenshot is identical to the previous one. Skipping analysis.');
          return;
        }
        
        // æ›´æ–°ä¸Šä¸€å¼µæˆªåœ–çš„ Data URL
        captureState.lastScreenshotDataUrl = dataUrl;
        
        // è™•ç†æˆªåœ–
        processScreenshot(dataUrl);
      });
    });
  }).catch(error => {
    console.error('[BACKGROUND_SCRIPT] Error getting screenshot setting:', error);
  });
}

// è™•ç†æˆªåœ–ä¸¦ç™¼é€çµ¦LLMåˆ†æž
function processScreenshot(screenshotDataUrl) {
  console.log('[BACKGROUND_SCRIPT] Processing screenshot');
  
  try {
    const timestamp = new Date().toISOString();
    
    // å¦‚æžœå•Ÿç”¨äº†ä¸‹è¼‰æª”æ¡ˆï¼Œä¿å­˜æˆªåœ–åˆ°æœ¬åœ°
    if (captureState.downloadFiles) {
      saveScreenshotToFile(screenshotDataUrl, timestamp);
    }
    
    // å¾žlocalStorageç²å–æˆªåœ–åˆ†æžè©³ç´°ç¨‹åº¦è¨­ç½®
    getFromStorage('screenshot_detail_level').then(screenshotDetailLevel => {
      const detailLevel = screenshotDetailLevel || 'medium'; // Default to medium
      
      // ç™¼é€æˆªåœ–çµ¦LLMé€²è¡Œåˆ†æž
      analyzeScreenshotWithLLM(screenshotDataUrl, timestamp, detailLevel);
    }).catch(error => {
      console.error('[BACKGROUND_SCRIPT] Error getting screenshot detail level:', error);
      // Use default if error
      analyzeScreenshotWithLLM(screenshotDataUrl, timestamp, 'medium');
    });
    
  } catch (error) {
    console.error('[BACKGROUND_SCRIPT] Screenshot processing failed:', error);
  }
}

// ä¿å­˜æˆªåœ–åˆ°æœ¬åœ°æª”æ¡ˆ
function saveScreenshotToFile(screenshotDataUrl, timestamp) {
  if (!captureState.activeTeamId) {
    console.warn('[BACKGROUND_SCRIPT] Cannot save screenshot: no active team ID');
    return;
  }
  
  const sanitizedTimestamp = timestamp.replace(/:/g, '-');
  const filename = `audio_capture/${captureState.activeTeamId}_screenshot_${sanitizedTimestamp}.jpg`;
  
  console.log(`[BACKGROUND_SCRIPT] Saving screenshot: ${filename}`);
  
  chrome.downloads.download({
    url: screenshotDataUrl,
    filename: filename,
    saveAs: false
  }, (downloadId) => {
    if (chrome.runtime.lastError) {
      console.error(`[BACKGROUND_SCRIPT] Error saving screenshot:`, chrome.runtime.lastError.message);
    } else {
      console.log(`[BACKGROUND_SCRIPT] Screenshot saved successfully. Download ID: ${downloadId}`);
    }
  });
}

// ä½¿ç”¨LLMåˆ†æžæˆªåœ–
function analyzeScreenshotWithLLM(screenshotDataUrl, timestamp, detailLevel = 'medium') {
  console.log(`[BACKGROUND_SCRIPT] Analyzing screenshot with LLM (Detail Level: ${detailLevel})`);
  
  // ä¸¦è¡Œç²å–æ‰€æœ‰éœ€è¦çš„è¨­ç½®
  Promise.all([
    getFromStorage('openai_api_key'),
    getFromStorage('openai_api_endpoint'),
    getFromStorage('openai_screenshot_model')
  ]).then(([apiKey, apiEndpoint, screenshotModel]) => {
    const endpoint = apiEndpoint || 'https://api.openai.com/v1';
    const model = screenshotModel || 'gpt-4o';
    
    console.log(`[BACKGROUND_SCRIPT] Screenshot analysis settings - Model: ${model}, Endpoint: ${endpoint}`);
    
    if (!apiKey) {
      console.error('[BACKGROUND_SCRIPT] No API key found for screenshot analysis');
      chrome.runtime.sendMessage({
        action: 'screenshotAnalysisError',
        error: 'No API key configured for screenshot analysis'
      });
      return;
    }
    
    if (!model) {
      console.error('[BACKGROUND_SCRIPT] No screenshot model selected');
      chrome.runtime.sendMessage({
        action: 'screenshotAnalysisError',
        error: 'No screenshot model selected in settings'
      });
      return;
    }
    
    // æº–å‚™APIè«‹æ±‚
    const baseApiUrl = endpoint.endsWith('/') ? endpoint.slice(0, -1) : endpoint;
    
    let promptText = "Please analyze this screenshot from a Teams meeting or presentation. Provide a concise summary of what you see, including any visible text, UI elements, presentation content, or meeting activities. Focus on information that would be relevant for meeting notes or evaluation purposes.";

    if (detailLevel === 'low') {
      promptText = "Provide a very brief, one-sentence summary of this screenshot, focusing on the main subject.";
    } else if (detailLevel === 'high') {
      promptText = "Provide a highly detailed and comprehensive analysis of this screenshot. Describe all visible text, UI elements, buttons, icons, presentation content (including titles, bullet points, images, charts, graphs), any people visible, and infer the current meeting activity or context. Be as exhaustive as possible.";
    }
    
    const requestBody = {
      model: model,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: promptText
            },
            {
              type: "image_url",
              image_url: {
                url: screenshotDataUrl
              }
            }
          ]
        }
      ],
      max_tokens: 500
    };
    
    fetch(`${baseApiUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    }).then(response => {
      if (!response.ok) {
        return response.text().then(errorText => {
          console.error('[BACKGROUND_SCRIPT] Screenshot analysis API error:', response.status, errorText);
          chrome.runtime.sendMessage({
            action: 'screenshotAnalysisError',
            error: `API error: ${response.status} - ${errorText}`
          });
        });
      }
      
      return response.json().then(result => {
        const analysis = result.choices?.[0]?.message?.content;
        
        if (analysis) {
          console.log('[BACKGROUND_SCRIPT] Screenshot analysis completed:', analysis);
          
          // å‰µå»ºæˆªåœ–åˆ†æžè¨˜éŒ„
          const screenshotAnalysis = {
            timestamp: timestamp,
            analysis: analysis,
            type: 'screenshot'
          };
          
          // ä¿å­˜åˆ°è½‰éŒ„ç‰‡æ®µä¸­ï¼ˆä½œç‚ºç‰¹æ®Šé¡žåž‹çš„è¨˜éŒ„ï¼‰
          captureState.transcriptChunks.push(screenshotAnalysis);
          
          // é€šçŸ¥popupæ›´æ–°
          chrome.runtime.sendMessage({
            action: 'screenshotAnalyzed',
            data: screenshotAnalysis
          });
          
          console.log('[BACKGROUND_SCRIPT] Screenshot analysis saved and notification sent');
        } else {
          console.warn('[BACKGROUND_SCRIPT] No analysis content received from LLM');
          chrome.runtime.sendMessage({
            action: 'screenshotAnalysisError',
            error: 'No analysis content received from AI model'
          });
        }
      });
    }).catch(error => {
      console.error('[BACKGROUND_SCRIPT] Screenshot analysis failed:', error);
      chrome.runtime.sendMessage({
        action: 'screenshotAnalysisError',
        error: `Screenshot analysis failed: ${error.message}`
      });
    });
  }).catch(error => {
    console.error('[BACKGROUND_SCRIPT] Error getting screenshot analysis settings:', error);
    chrome.runtime.sendMessage({
      action: 'screenshotAnalysisError',
      error: `Failed to get settings: ${error.message}`
    });
  });
}

// è¼”åŠ©å‡½æ•¸ï¼šå¾žlocalStorageç²å–æ•¸æ“š
function getFromStorage(key) {
  return new Promise((resolve) => {
    chrome.storage.local.get([key], (result) => {
      if (chrome.runtime.lastError) {
        console.error(`[BACKGROUND_SCRIPT] chrome.storage.local error for key '${key}':`, chrome.runtime.lastError);
        resolve(null);
      } else {
        const value = result[key];
        console.log(`[BACKGROUND_SCRIPT] getFromStorage('${key}'):`, value ? 'Found' : 'Not found');
        resolve(value);
      }
    });
  });
}

// åœ¨èƒŒæ™¯è™•ç†éŸ³é »è½‰æ–‡å­—
function processAudioChunkInBackground(audioBase64, timestamp, isFinal) {
  console.log('[BACKGROUND_SCRIPT] Processing audio chunk in background:', timestamp);
  console.log('[BACKGROUND_SCRIPT] Is final chunk:', isFinal ? 'Yes' : 'No');
  
  // ä¸¦è¡Œç²å–APIè¨­ç½®
  Promise.all([
    getFromStorage('openai_api_key'),
    getFromStorage('openai_api_endpoint'),
    getFromStorage('transcription_language')
  ]).then(([apiKey, apiEndpoint, selectedLanguage]) => {
    const endpoint = apiEndpoint || 'https://api.openai.com/v1';
    const language = selectedLanguage || '';
    
    if (!apiKey) {
      console.error('[BACKGROUND_SCRIPT] No API key found for transcription');
      chrome.runtime.sendMessage({
        action: 'transcriptionError',
        error: 'No OpenAI API key configured'
      });
      return;
    }
    
    // å»ºç«‹éŸ³è¨Šæª”æ¡ˆ
    const audioBlob = base64ToBlob(audioBase64, 'audio/webm');
    
    if (audioBlob.size < 100) {
      console.error('[BACKGROUND_SCRIPT] Audio blob is too small, likely contains no audio data');
      return;
    }
    
    // ç¢ºä¿ API ç«¯é»žä¸ä»¥æ–œæ§“çµå°¾
    const baseApiUrl = endpoint.endsWith('/') ? endpoint.slice(0, -1) : endpoint;
    console.log(`[BACKGROUND_SCRIPT] Using API endpoint for transcription: ${baseApiUrl}`);
    
    // å»ºç«‹FormData
    const formData = new FormData();
    formData.append('file', audioBlob, 'audio.webm');
    formData.append('model', 'whisper-1');
    
    // æ·»åŠ èªžè¨€åƒæ•¸ï¼ˆå¦‚æžœç”¨æˆ¶æœ‰é¸æ“‡çš„è©±ï¼‰
    if (language) {
      formData.append('language', language);
      console.log(`[BACKGROUND_SCRIPT] Using language: ${language}`);
    } else {
      console.log('[BACKGROUND_SCRIPT] Using auto-detect language');
    }
    
    // èª¿ç”¨APIé€²è¡Œè½‰éŒ„
    fetch(`${baseApiUrl}/audio/transcriptions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`
      },
      body: formData
    }).then(response => {
      if (!response.ok) {
        return response.text().then(errorText => {
          console.error('[BACKGROUND_SCRIPT] Transcription API error:', response.status, errorText);
          chrome.runtime.sendMessage({
            action: 'transcriptionError',
            error: `API error: ${response.status} - ${errorText}`
          });
        });
      }
      
      return response.json().then(result => {
        // Check if transcription has content
        if (!result.text || result.text.trim() === '') {
          console.warn('[BACKGROUND_SCRIPT] Transcription returned empty text');
          return;
        }
        
        // ä¿å­˜è½‰éŒ„çµæžœ
        const transcriptChunk = {
          timestamp: timestamp,
          text: result.text,
          isFinal: isFinal || false
        };
        
        // ä¿å­˜åˆ° background state
        captureState.transcriptChunks.push(transcriptChunk);
        console.log('[BACKGROUND_SCRIPT] Transcription completed and saved:', result.text);
        
        // é€šçŸ¥æ‰€æœ‰æ‰“é–‹çš„ extension é é¢æ›´æ–°
        chrome.runtime.sendMessage({
          action: 'transcriptUpdated',
          transcriptChunks: captureState.transcriptChunks
        });
        
        // å¦‚æžœæ˜¯æœ€å¾Œä¸€å€‹å€å¡Šï¼Œä¿å­˜åˆ°åœ˜éšŠè¨˜éŒ„
        if (isFinal) {
          console.log('[BACKGROUND_SCRIPT] Final chunk received, preparing to save transcript to team');
          // å»¶é²ä¿å­˜ä»¥ç¢ºä¿æ‰€æœ‰è™•ç†å®Œæˆ
          setTimeout(() => {
            saveTranscriptToTeamInBackground();
          }, 1000);
        }
      });
    }).catch(error => {
      console.error('[BACKGROUND_SCRIPT] Audio processing failed:', error);
      chrome.runtime.sendMessage({
        action: 'transcriptionError',
        error: `Audio processing failed: ${error.message}`
      });
    });
  }).catch(error => {
    console.error('[BACKGROUND_SCRIPT] Error getting transcription settings:', error);
    chrome.runtime.sendMessage({
      action: 'transcriptionError',
      error: `Failed to get settings: ${error.message}`
    });
  });
}

// base64è½‰Blob (åœ¨backgroundä¸­ä½¿ç”¨)
function base64ToBlob(base64, mimeType) {
  const byteCharacters = atob(base64);
  const byteArrays = [];
  
  for (let offset = 0; offset < byteCharacters.length; offset += 512) {
    const slice = byteCharacters.slice(offset, offset + 512);
    
    const byteNumbers = new Array(slice.length);
    for (let i = 0; i < slice.length; i++) {
      byteNumbers[i] = slice.charCodeAt(i);
    }
    
    const byteArray = new Uint8Array(byteNumbers);
    byteArrays.push(byteArray);
  }
  
  return new Blob(byteArrays, { type: mimeType });
}

// åœ¨èƒŒæ™¯ä¸­ä¿å­˜è½‰éŒ„åˆ°åœ˜éšŠè¨˜éŒ„
function saveTranscriptToTeamInBackground() {
  try {
    console.log('[BACKGROUND_SCRIPT] saveTranscriptToTeamInBackground - Starting to save transcript');
    console.log('[BACKGROUND_SCRIPT] Active team ID:', captureState.activeTeamId);
    console.log('[BACKGROUND_SCRIPT] Transcript chunks length:', captureState.transcriptChunks.length);
    console.log('[BACKGROUND_SCRIPT] Transcript chunks:', JSON.stringify(captureState.transcriptChunks, null, 2));
    
    if (!captureState.activeTeamId) {
      console.warn('[BACKGROUND_SCRIPT] Cannot save transcript: no active team ID');
      chrome.runtime.sendMessage({
        action: 'transcriptionError',
        error: 'Cannot save transcript: no active team selected'
      });
      return false;
    }
    
    if (captureState.transcriptChunks.length === 0) {
      console.warn('[BACKGROUND_SCRIPT] Cannot save transcript: empty chunks');
      chrome.runtime.sendMessage({
        action: 'transcriptionError',
        error: 'Cannot save transcript: no transcription data available'
      });
      return false;
    }
    
    const fullText = captureState.transcriptChunks.map(chunk => {
      if (chunk.type === 'screenshot') {
        return `[ðŸ“¸ ${chunk.analysis}]`;
      }
      return chunk.text || chunk.analysis || '';
    }).join(' ');
    
    console.log('[BACKGROUND_SCRIPT] Full text to save:', fullText);
    
    // é€šçŸ¥å‰ç«¯ä¿å­˜è½‰éŒ„è¨˜éŒ„
    const messageToSend = {
      action: 'saveTranscriptToTeam',
      teamId: captureState.activeTeamId,
      transcriptChunks: captureState.transcriptChunks,
      fullText: fullText
    };
    
    console.log('[BACKGROUND_SCRIPT] Sending message to popup:', JSON.stringify(messageToSend, null, 2));
    
    chrome.runtime.sendMessage(messageToSend, (response) => {
      if (chrome.runtime.lastError) {
        console.error('[BACKGROUND_SCRIPT] Error sending save message:', chrome.runtime.lastError);
      } else {
        console.log('[BACKGROUND_SCRIPT] Save message sent successfully, response:', response);
      }
    });
    
    console.log('[BACKGROUND_SCRIPT] Transcript save request sent to frontend');
    return true;
    
  } catch (error) {
    console.error('[BACKGROUND_SCRIPT] saveTranscriptToTeamInBackground error:', error);
    chrome.runtime.sendMessage({
      action: 'transcriptionError',
      error: `Failed to save transcript: ${error.message}`
    });
    return false;
  }
}